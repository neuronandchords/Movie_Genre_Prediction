# -*- coding: utf-8 -*-
"""Copy of model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18pzIofHjNH2o8VdLKMhlS3JWkGBlhLHF
"""

# Commented out IPython magic to ensure Python compatibility.
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.utils import to_categorical
from keras.preprocessing import image
import PIL
from PIL import Image
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tqdm import tqdm
# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive')

train=pd.read_csv("/content/drive/My Drive/Multi_Label_dataset.zip (Unzipped Files)/Multi_Label_dataset/train.csv")

train.head()

train.describe()

train_image = []
for i in tqdm(range(train.shape[0])):
    img = image.load_img(r"/content/drive/My Drive/Multi_Label_dataset.zip (Unzipped Files)/Multi_Label_dataset/Images/"+train['Id'][i]+'.jpg',target_size=(250,250,3))
    img = image.img_to_array(img)
    img = img/255
    train_image.append(img)
X = np.array(train_image)

X.shape

plt.imshow(X[1890])

y = np.array(train.drop(['Id', 'Genre'],axis=1))
y.shape

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.1)

model = Sequential()
model.add(Conv2D(filters=16, kernel_size=(5, 5), activation="relu", input_shape=(250,250,3)))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Conv2D(filters=64, kernel_size=(5, 5), activation="relu"))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(25, activation='sigmoid'))

model.summary()

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), batch_size=64)

img = image.load_img('/content/drive/My Drive/Multi_Label_dataset.zip (Unzipped Files)/Multi_Label_dataset/Test images/daenerys-targaryen-game-of-thrones-8-750x1334_578965-mm-90.jpg',target_size=(250,250,3))
img = image.img_to_array(img)
img = img/255

classes = np.array(train.columns[2:])
proba = model.predict(img.reshape(1,250,250,3))
top_3 = np.argsort(proba[0])[:-4:-1]
for i in range(3):
    print("{}".format(classes[top_3[i]])+" ({:.3})".format(proba[0][top_3[i]]))
plt.imshow(img)

img = image.load_img('/content/drive/My Drive/Multi_Label_dataset.zip (Unzipped Files)/Multi_Label_dataset/Test images/MV5BMTllZDJhMTAtMjhmZi00MzBjLTljMmQtMmNlYTAwYmY0Y2Q0XkEyXkFqcGdeQXVyNDUzOTQ5MjY@._V1_UY1200_CR108,0,630,1200_AL_.jpg',target_size=(250,250,3))
img = image.img_to_array(img)
img = img/255

classes = np.array(train.columns[2:])
proba = model.predict(img.reshape(1,250,250,3))
top_3 = np.argsort(proba[0])[:-4:-1]
for i in range(3):
    print("{}".format(classes[top_3[i]])+" ({:.3})".format(proba[0][top_3[i]]))
plt.imshow(img)

img = image.load_img('/content/drive/My Drive/Multi_Label_dataset.zip (Unzipped Files)/Multi_Label_dataset/Test images/53044759.webp',target_size=(250,250,3))
img = image.img_to_array(img)
img = img/255

classes = np.array(train.columns[2:])
proba = model.predict(img.reshape(1,250,250,3))
top_3 = np.argsort(proba[0])[:-4:-1]
for i in range(3):
    print("{}".format(classes[top_3[i]])+" ({:.3})".format(proba[0][top_3[i]]))
plt.imshow(img)

img = image.load_img('/content/drive/My Drive/Multi_Label_dataset.zip (Unzipped Files)/Multi_Label_dataset/Test images/8b6b3092c1814681cda727f656ddfcba.jpg',target_size=(250,250,3))
img = image.img_to_array(img)
img = img/255

classes = np.array(train.columns[2:])
proba = model.predict(img.reshape(1,250,250,3))
top_3 = np.argsort(proba[0])[:-4:-1]
for i in range(3):
    print("{}".format(classes[top_3[i]])+" ({:.3})".format(proba[0][top_3[i]]))
plt.imshow(img)

model.save('/content/drive/My Drive/Multi_Label_dataset.zip (Unzipped Files)/Multi_Label_dataset/model.h5')

img = image.load_img('/content/Raanjhanaa.jpg',target_size=(250,250,3))
img = image.img_to_array(img)
img = img/255

classes = np.array(train.columns[2:])
proba = model.predict(img.reshape(1,250,250,3))
top_3 = np.argsort(proba[0])[:-4:-1]
for i in range(3):
    print("{}".format(classes[top_3[i]])+" ({:.3})".format(proba[0][top_3[i]]))
plt.imshow(img)

model_json = model.to_json()
with open("model.json", "w") as json_file:
    json_file.write(model_json)
# serialize weights to HDF5
model.save_weights("model.h5")
print("Saved model to disk")

from keras.models import model_from_json
json_file = open('model.json', 'r')
loaded_model_json = json_file.read()
json_file.close()
loaded_model = model_from_json(loaded_model_json)
# load weights into new model
loaded_model.load_weights("model.h5")
print("Loaded model from disk")

loaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
score = loaded_model.evaluate(X_test, y_test, verbose=0)
print("%s: %.2f%%" % (loaded_model.metrics_names[1], score[1]*100))

"""**Great Job Amaya!**"""